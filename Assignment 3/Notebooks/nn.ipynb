{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import  torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = data.iloc[:, 3:]\n",
    "y = data.iloc[:, 1:3]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_FEATURES = len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "train_dataset = RegressionDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())\n",
    "test_dataset = RegressionDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float())\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 10)\n",
    "        self.fc2 = nn.Linear(10, 12)\n",
    "        self.fc3 = nn.Linear(12, 20)\n",
    "        self.fc4 = nn.Linear(20, 12)\n",
    "        self.fc5 = nn.Linear(12, 10)\n",
    "        self.fc6 = nn.Linear(10, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.dropout(self.fc1(inputs)))\n",
    "        x = self.relu(self.dropout(self.fc2(x)))\n",
    "        x = self.relu(self.dropout(self.fc3(x)))\n",
    "        x = self.relu(self.dropout(self.fc4(x)))\n",
    "        x = self.relu(self.dropout(self.fc5(x)))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, test_inputs):\n",
    "        x = self.relu(self.fc1(test_inputs))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN(\n",
      "  (fc1): Linear(in_features=6, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=12, bias=True)\n",
      "  (fc3): Linear(in_features=12, out_features=20, bias=True)\n",
      "  (fc4): Linear(in_features=20, out_features=12, bias=True)\n",
      "  (fc5): Linear(in_features=12, out_features=10, bias=True)\n",
      "  (fc6): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ANN(NUM_FEATURES).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN(NUM_FEATURES).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "loss_stats = {\"train\" : [], \"test\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training!!\n",
      "Epoch 1: | Train Loss: 14.54848\n",
      "Epoch 2: | Train Loss: 11.42260\n",
      "Epoch 3: | Train Loss: 11.19509\n",
      "Epoch 4: | Train Loss: 11.05411\n",
      "Epoch 5: | Train Loss: 10.90995\n",
      "Epoch 6: | Train Loss: 10.83637\n",
      "Epoch 7: | Train Loss: 10.76522\n",
      "Epoch 8: | Train Loss: 10.72551\n",
      "Epoch 9: | Train Loss: 10.68430\n",
      "Epoch 10: | Train Loss: 10.65908\n",
      "Epoch 11: | Train Loss: 10.63203\n",
      "Epoch 12: | Train Loss: 10.60279\n",
      "Epoch 13: | Train Loss: 10.55002\n",
      "Epoch 14: | Train Loss: 10.53477\n",
      "Epoch 15: | Train Loss: 10.49371\n",
      "Epoch 16: | Train Loss: 10.48036\n",
      "Epoch 17: | Train Loss: 10.47342\n",
      "Epoch 18: | Train Loss: 10.45329\n",
      "Epoch 19: | Train Loss: 10.44321\n",
      "Epoch 20: | Train Loss: 10.42964\n",
      "Epoch 21: | Train Loss: 10.41264\n",
      "Epoch 22: | Train Loss: 10.40726\n",
      "Epoch 23: | Train Loss: 10.40710\n",
      "Epoch 24: | Train Loss: 10.39566\n",
      "Epoch 25: | Train Loss: 10.39069\n",
      "Epoch 26: | Train Loss: 10.38748\n",
      "Epoch 27: | Train Loss: 10.36426\n",
      "Epoch 28: | Train Loss: 10.36624\n",
      "Epoch 29: | Train Loss: 10.35305\n",
      "Epoch 30: | Train Loss: 10.35634\n",
      "Epoch 31: | Train Loss: 10.34286\n",
      "Epoch 32: | Train Loss: 10.34032\n",
      "Epoch 33: | Train Loss: 10.32861\n",
      "Epoch 34: | Train Loss: 10.32971\n",
      "Epoch 35: | Train Loss: 10.32619\n",
      "Epoch 36: | Train Loss: 10.32538\n",
      "Epoch 37: | Train Loss: 10.31905\n",
      "Epoch 38: | Train Loss: 10.30593\n",
      "Epoch 39: | Train Loss: 10.30549\n",
      "Epoch 40: | Train Loss: 10.30567\n",
      "Epoch 41: | Train Loss: 10.30229\n",
      "Epoch 42: | Train Loss: 10.28923\n",
      "Epoch 43: | Train Loss: 10.29276\n",
      "Epoch 44: | Train Loss: 10.28771\n",
      "Epoch 45: | Train Loss: 10.28598\n",
      "Epoch 46: | Train Loss: 10.28377\n",
      "Epoch 47: | Train Loss: 10.27657\n",
      "Epoch 48: | Train Loss: 10.26996\n",
      "Epoch 49: | Train Loss: 10.26656\n",
      "Epoch 50: | Train Loss: 10.26665\n",
      "Epoch 51: | Train Loss: 10.26674\n",
      "Epoch 52: | Train Loss: 10.25585\n",
      "Epoch 53: | Train Loss: 10.25136\n",
      "Epoch 54: | Train Loss: 10.25909\n",
      "Epoch 55: | Train Loss: 10.25390\n",
      "Epoch 56: | Train Loss: 10.25503\n",
      "Epoch 57: | Train Loss: 10.25037\n",
      "Epoch 58: | Train Loss: 10.24139\n",
      "Epoch 59: | Train Loss: 10.24334\n",
      "Epoch 60: | Train Loss: 10.23711\n",
      "Epoch 61: | Train Loss: 10.23935\n",
      "Epoch 62: | Train Loss: 10.23945\n",
      "Epoch 63: | Train Loss: 10.23029\n",
      "Epoch 64: | Train Loss: 10.23105\n",
      "Epoch 65: | Train Loss: 10.22887\n",
      "Epoch 66: | Train Loss: 10.22397\n",
      "Epoch 67: | Train Loss: 10.22190\n",
      "Epoch 68: | Train Loss: 10.21842\n",
      "Epoch 69: | Train Loss: 10.21795\n",
      "Epoch 70: | Train Loss: 10.21737\n",
      "Epoch 71: | Train Loss: 10.21682\n",
      "Epoch 72: | Train Loss: 10.21237\n",
      "Epoch 73: | Train Loss: 10.21374\n",
      "Epoch 74: | Train Loss: 10.21015\n",
      "Epoch 75: | Train Loss: 10.21117\n",
      "Epoch 76: | Train Loss: 10.20909\n",
      "Epoch 77: | Train Loss: 10.20545\n",
      "Epoch 78: | Train Loss: 10.20605\n",
      "Epoch 79: | Train Loss: 10.20134\n",
      "Epoch 80: | Train Loss: 10.19903\n",
      "Epoch 81: | Train Loss: 10.20457\n",
      "Epoch 82: | Train Loss: 10.20098\n",
      "Epoch 83: | Train Loss: 10.19222\n",
      "Epoch 84: | Train Loss: 10.19559\n",
      "Epoch 85: | Train Loss: 10.19429\n",
      "Epoch 86: | Train Loss: 10.19307\n",
      "Epoch 87: | Train Loss: 10.18809\n",
      "Epoch 88: | Train Loss: 10.18790\n",
      "Epoch 89: | Train Loss: 10.19167\n",
      "Epoch 90: | Train Loss: 10.18380\n",
      "Epoch 91: | Train Loss: 10.18422\n",
      "Epoch 92: | Train Loss: 10.18320\n",
      "Epoch 93: | Train Loss: 10.18324\n",
      "Epoch 94: | Train Loss: 10.17851\n",
      "Epoch 95: | Train Loss: 10.18166\n",
      "Epoch 96: | Train Loss: 10.17680\n",
      "Epoch 97: | Train Loss: 10.17495\n",
      "Epoch 98: | Train Loss: 10.17431\n",
      "Epoch 99: | Train Loss: 10.17069\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin Training!!\")\n",
    "\n",
    "for epoch in range(1, EPOCHS):\n",
    "    train_epoch_loss = 0\n",
    "    for idx, (X_train_batch, y_train_batch) in enumerate(train_dataloader):\n",
    "        X_train_batch = X_train_batch.to(device)\n",
    "        y_train_batch = y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_train_preds = model(X_train_batch)\n",
    "        train_loss = criterion(y_train_preds, y_train_batch.unsqueeze(1))\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        \n",
    "    loss_stats[\"train\"].append(train_epoch_loss)\n",
    "    print(f'Epoch {epoch}: | Train Loss: {train_epoch_loss/len(train_dataloader):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_batch, _ in test_dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_pred_list.append(y_test_pred.cpu().numpy())\n",
    "        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 2)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_list = np.array(y_pred_list[0])\n",
    "# y\n",
    "y_pred_list.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
